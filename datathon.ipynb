{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.0 Importando bibliotecas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np  \n",
    "import pandas as pd  \n",
    "import datetime as dt  \n",
    "import warnings  \n",
    "import re\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt  \n",
    "import seaborn as sns  \n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.0 Extração e Tratamento dos dados\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extraíndo arquivo das informações dos candidatos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_applicants = pd.read_json('bases/applicants.json', orient='index')\n",
    "\n",
    "infos_basicas = pd.json_normalize(df_applicants['infos_basicas'])\n",
    "informacoes_pessoais = pd.json_normalize(df_applicants['informacoes_pessoais'])\n",
    "informacoes_profissionais = pd.json_normalize(df_applicants['informacoes_profissionais'])\n",
    "formacao_e_idiomas = pd.json_normalize(df_applicants['formacao_e_idiomas'])\n",
    "cargo_atual = pd.json_normalize(df_applicants['cargo_atual'])\n",
    "\n",
    "df_applicants = pd.concat([infos_basicas, informacoes_pessoais, informacoes_profissionais, formacao_e_idiomas, cargo_atual], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extraíndo arquivo das vagas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vagas = pd.read_json('bases/vagas.json', orient='index')\n",
    "\n",
    "df_vagas.reset_index(inplace=True)\n",
    "df_vagas.rename(columns={\"index\": \"codigo_vaga\"}, inplace=True)\n",
    "\n",
    "df_info_basicas = pd.json_normalize(df_vagas['informacoes_basicas'])\n",
    "df_perfil_vaga = pd.json_normalize(df_vagas['perfil_vaga']) \n",
    "df_beneficios = pd.json_normalize(df_vagas['beneficios'])  \n",
    "\n",
    "df_vagas = pd.concat([df_vagas[['codigo_vaga']], df_info_basicas, df_perfil_vaga, df_beneficios], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extraíndo arquivo dos candidatos prospectados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prospects = pd.read_json('bases/prospects.json', orient='index')\n",
    "\n",
    "df_prospects.reset_index(inplace=True)\n",
    "df_prospects.rename(columns={\"index\": \"codigo_vaga\"}, inplace=True)\n",
    "\n",
    "df_prospects = df_prospects.explode('prospects').reset_index(drop=True)\n",
    "df_prospects_detalhado = pd.json_normalize(df_prospects['prospects'])  # Removido o .add_prefix()\n",
    "df_prospects = pd.concat([df_prospects.drop(columns=['prospects']), df_prospects_detalhado], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Tratando a tabela df_applicants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove colunas duplicadas resultantes da concatenação dos blocos normalizados de dados dos candidatos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_applicants = df_applicants.loc[:, ~df_applicants.columns.duplicated(keep='first')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['telefone_recado', 'telefone', 'objetivo_profissional', 'data_criacao',\n",
       "       'inserido_por', 'email', 'local', 'sabendo_de_nos_por',\n",
       "       'data_atualizacao', 'codigo_profissional', 'nome', 'data_aceite', 'cpf',\n",
       "       'fonte_indicacao', 'email_secundario', 'data_nascimento',\n",
       "       'telefone_celular', 'sexo', 'estado_civil', 'pcd', 'endereco', 'skype',\n",
       "       'url_linkedin', 'facebook', 'download_cv', 'titulo_profissional',\n",
       "       'area_atuacao', 'conhecimentos_tecnicos', 'certificacoes',\n",
       "       'outras_certificacoes', 'remuneracao', 'nivel_profissional',\n",
       "       'qualificacoes', 'experiencias', 'nivel_academico', 'nivel_ingles',\n",
       "       'nivel_espanhol', 'outro_idioma', 'instituicao_ensino_superior',\n",
       "       'cursos', 'ano_conclusao', 'outro_curso', 'id_ibrati',\n",
       "       'email_corporativo', 'cargo_atual', 'projeto_atual', 'cliente',\n",
       "       'unidade', 'data_admissao', 'data_ultima_promocao',\n",
       "       'nome_superior_imediato', 'email_superior_imediato', 'empresa', 'cargo',\n",
       "       'data_inicio', 'data_fim', 'principais_atividades'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_applicants.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selecionando apenas as colunas desejadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "colunas_applicants = [\n",
    "    \"codigo_profissional\",\"objetivo_profissional\",\n",
    "    \"pcd\", \"area_atuacao\",\n",
    "    \"conhecimentos_tecnicos\",\"certificacoes\",\"outras_certificacoes\",\n",
    "    \"nivel_profissional\", \"nivel_academico\", \"nivel_ingles\",\n",
    "    \"nivel_espanhol\",\"outro_idioma\",\"cursos\",\"cargo_atual\",\"local\"\n",
    "]\n",
    "\n",
    "df_applicants = df_applicants[colunas_applicants]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42483, 15)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_applicants.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validando dados Nulls e brancos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "codigo_profissional           0\n",
       "objetivo_profissional         0\n",
       "pcd                           0\n",
       "area_atuacao                  0\n",
       "conhecimentos_tecnicos        0\n",
       "certificacoes                 0\n",
       "outras_certificacoes          0\n",
       "nivel_profissional            0\n",
       "nivel_academico               0\n",
       "nivel_ingles                  0\n",
       "nivel_espanhol                0\n",
       "outro_idioma                  0\n",
       "cursos                    35274\n",
       "cargo_atual               41539\n",
       "local                         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_applicants.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "codigo_profissional           0\n",
       "objetivo_profissional     14416\n",
       "pcd                       36161\n",
       "area_atuacao              35731\n",
       "conhecimentos_tecnicos    39129\n",
       "certificacoes             41954\n",
       "outras_certificacoes      41584\n",
       "nivel_profissional        42402\n",
       "nivel_academico           34388\n",
       "nivel_ingles              35638\n",
       "nivel_espanhol            35795\n",
       "outro_idioma                  0\n",
       "cursos                     1070\n",
       "cargo_atual                 546\n",
       "local                     25474\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df_applicants == \"\").sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "codigo_profissional       0.00\n",
      "objetivo_profissional     0.34\n",
      "pcd                       0.85\n",
      "area_atuacao              0.84\n",
      "conhecimentos_tecnicos    0.92\n",
      "certificacoes             0.99\n",
      "outras_certificacoes      0.98\n",
      "nivel_profissional        1.00\n",
      "nivel_academico           0.81\n",
      "nivel_ingles              0.84\n",
      "nivel_espanhol            0.84\n",
      "outro_idioma              0.00\n",
      "cursos                    0.03\n",
      "cargo_atual               0.01\n",
      "local                     0.60\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "percentuais_vazios = (df_applicants == \"\").sum() / df_applicants.shape[0]\n",
    "print(percentuais_vazios.round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para garantir a qualidade dos dados e remover entradas indesejadas ou inválidas, criamos uma função que limpa as colunas de informações, removendo valores como e-mails, datas, e dados vazios. O objetivo é manter apenas entradas com caracteres alfabéticos relevantes para a análise.\n",
    "\n",
    "#### Lógica da Função:\n",
    "- **E-mails**: Se a entrada for um endereço de e-mail (identificado por um padrão regex), ela será removida.\n",
    "- **Datas**: Caso o valor seja reconhecido como uma data válida, ele será descartado.\n",
    "- **Vazios e ruídos**: Entradas vazias, com pontos, hífens ou espaços em branco também são removidas.\n",
    "- **Caracteres alfabéticos**: A função mantém apenas entradas que contêm caracteres alfabéticos (a, b, c, ... Z).\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filtrar_somente_caracteres(df, coluna):\n",
    "    def limpar_objetivo(obj):\n",
    "        obj = str(obj).strip() \n",
    "        \n",
    "        if pd.isna(obj) or obj in [\"\", \".\", \"-\", \" \"]:\n",
    "            return \"\"\n",
    "             \n",
    "        if re.match(r\"^[\\w\\.-]+@[\\w\\.-]+\\.[a-zA-Z]{2,}$\", obj):\n",
    "            return \"\"\n",
    "        \n",
    "        if pd.to_datetime(obj, errors='coerce') is not pd.NaT:\n",
    "            return \"\"\n",
    "        \n",
    "        if not re.search(r\"[a-zA-Z]\", obj):\n",
    "            return \"\"\n",
    "        \n",
    "        obj = obj.replace('nan', '') \n",
    "        \n",
    "        return obj  \n",
    "\n",
    "    df[coluna] = df[coluna].apply(limpar_objetivo)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "colunas_para_limpar = [\n",
    "    \"objetivo_profissional\", \"pcd\", \"area_atuacao\", \"conhecimentos_tecnicos\",\n",
    "    \"certificacoes\", \"outras_certificacoes\", \"nivel_profissional\", \"nivel_academico\",\n",
    "    \"nivel_ingles\", \"nivel_espanhol\", \"outro_idioma\", \"cursos\", \"cargo_atual\", \"local\"\n",
    "]\n",
    "\n",
    "for coluna in colunas_para_limpar:\n",
    "    df_applicants = filtrar_somente_caracteres(df_applicants, coluna)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retirando todas as linhas onde o objetivo profissional for vazio, pois usaremos essa coluna como nossa principal, por possuir menos dados relevantes vazios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_applicants = df_applicants[df_applicants['objetivo_profissional'] != '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27995, 15)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_applicants.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "codigo_profissional           0\n",
       "objetivo_profissional         0\n",
       "pcd                       22150\n",
       "area_atuacao              21761\n",
       "conhecimentos_tecnicos    24777\n",
       "certificacoes             27508\n",
       "outras_certificacoes      27150\n",
       "nivel_profissional        27931\n",
       "nivel_academico           20455\n",
       "nivel_ingles              21734\n",
       "nivel_espanhol            21837\n",
       "outro_idioma              26681\n",
       "cursos                    22256\n",
       "cargo_atual               27639\n",
       "local                     11665\n",
       "dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df_applicants == \"\").sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para facilitar o processamento de texto, especialmente em tarefas de NLP (Natural Language Processing), criamos uma função que concatena várias colunas em um único campo. Isso permite que possamos trabalhar com informações de maneira mais eficiente, sem a necessidade de analisar colunas individualmente.\n",
    "\n",
    "#### Lógica:\n",
    "- **Filtro de valores vazios**: Quando uma coluna contém um valor em branco, ela é ignorada na concatenação da linha. Isso é importante para evitar a inclusão de dados irrelevantes (ruídos) no modelo, o que pode prejudicar a qualidade da análise.\n",
    "- **Concatenando as colunas**: As colunas selecionadas para cada grupo de informações são unidas em uma string, com um separador \" | \", de modo a manter as informações organizadas e separadas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def criar_grupos_concatenados(df, id_coluna, grupos_colunas):\n",
    "    dfs_resultado = {}\n",
    "\n",
    "    for nome_grupo, colunas in grupos_colunas.items():\n",
    "        df_temp = df[[id_coluna] + colunas].copy()\n",
    "\n",
    "        def concatenar_linha(row):\n",
    "            textos_validos = [\n",
    "                f\"{coluna}: {str(row[coluna]).strip()}\"\n",
    "                for coluna in colunas\n",
    "                if str(row[coluna]).strip() != \"\"\n",
    "            ]\n",
    "            return ' | '.join(textos_validos)\n",
    "\n",
    "        df_temp[f\"perfil_concatenado_{nome_grupo}\"] = df_temp.apply(concatenar_linha, axis=1)\n",
    "\n",
    "        df_temp = df_temp[df_temp[f\"perfil_concatenado_{nome_grupo}\"] != \"\"]\n",
    "\n",
    "        dfs_resultado[nome_grupo] = df_temp[[id_coluna, f\"perfil_concatenado_{nome_grupo}\"]]\n",
    "\n",
    "    return dfs_resultado\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para aplicar diferentes pesos nas habilidades durante o modelo de similaridade, separamos as colunas de dados em três grupos distintos: **Hard Skills**, **Educação** e **Personal**. Esta organização facilita a aplicação de pesos personalizados em cada grupo, dependendo da sua importância no modelo.\n",
    "\n",
    "#### Etapas:\n",
    "\n",
    "1. **Definição dos grupos**:\n",
    "   - **Hard Skills**: Inclui informações como objetivos profissionais, área de atuação, conhecimentos técnicos, cargo atual, etc.\n",
    "   - **Educação**: Engloba certificações, níveis acadêmicos e fluência em idiomas.\n",
    "   - **Pessoais**: Contém dados sobre pessoas com deficiência (PCD) e a localização dos candidatos.\n",
    "\n",
    "2. **Criação de grupos concatenados**:\n",
    "   Para cada grupo, concatenamos as informações das colunas relevantes. Caso uma coluna contenha dados vazios ou inválidos, esses valores são excluídos, como feito no passo anterior.\n",
    "\n",
    "3. **Mesclagem dos DataFrames**:\n",
    "   Os DataFrames de cada grupo são mesclados em um único DataFrame `df_unico`, utilizando `outer join` para garantir que todas as informações sejam mantidas, mesmo que algumas colunas não possuam valores para certos candidatos.\n",
    "\n",
    "4. **Preenchimento de valores ausentes**:\n",
    "      Utilizamos `fillna('')` para substituir valores `NaN` por strings vazias, garantindo que o modelo de similaridade não seja afetado por dados faltantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "hard_skills = [\n",
    "    \"objetivo_profissional\",\n",
    "    \"area_atuacao\",\n",
    "    \"conhecimentos_tecnicos\",\n",
    "    \"nivel_profissional\",\n",
    "    \"cargo_atual\",\n",
    "    \"cursos\"\n",
    "]\n",
    "\n",
    "education = [\n",
    "    \"certificacoes\",\n",
    "    \"outras_certificacoes\",\n",
    "    \"nivel_academico\",\n",
    "    \"nivel_ingles\",\n",
    "    \"nivel_espanhol\",\n",
    "    \"outro_idioma\"\n",
    "]\n",
    "\n",
    "personal = [\n",
    "    \"pcd\",\n",
    "    \"local\"\n",
    "]\n",
    "\n",
    "grupos_colunas = {\n",
    "    \"hard_skills\": hard_skills,\n",
    "    \"education\": education,\n",
    "    \"personal\": personal\n",
    "}\n",
    "\n",
    "dfs_por_grupo = criar_grupos_concatenados(df_applicants, \"codigo_profissional\", grupos_colunas)\n",
    "\n",
    "df_hard_skills = dfs_por_grupo[\"hard_skills\"]\n",
    "df_education = dfs_por_grupo[\"education\"]\n",
    "df_personal = dfs_por_grupo[\"personal\"]\n",
    "\n",
    "df_unico = df_hard_skills.merge(df_education, on=\"codigo_profissional\", how=\"outer\")\n",
    "df_unico = df_unico.merge(df_personal, on=\"codigo_profissional\", how=\"outer\")\n",
    "\n",
    "df_unico.fillna('',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "codigo_profissional                   0\n",
       "perfil_concatenado_hard_skills        0\n",
       "perfil_concatenado_education      20428\n",
       "perfil_concatenado_personal       11664\n",
       "dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df_unico == \"\").sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "codigo_profissional               object\n",
       "perfil_concatenado_hard_skills    object\n",
       "perfil_concatenado_education      object\n",
       "perfil_concatenado_personal       object\n",
       "dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_unico.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unico['codigo_profissional'] = df_unico['codigo_profissional'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  1.2 Tratando a tabela df_prospects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['codigo_vaga', 'titulo', 'modalidade', 'nome', 'codigo',\n",
       "       'situacao_candidado', 'data_candidatura', 'ultima_atualizacao',\n",
       "       'comentario', 'recrutador'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_prospects.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(56702, 10)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_prospects.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "codigo_vaga              0\n",
       "titulo                   0\n",
       "modalidade               0\n",
       "nome                  2943\n",
       "codigo                2943\n",
       "situacao_candidado    2943\n",
       "data_candidatura      2943\n",
       "ultima_atualizacao    2943\n",
       "comentario            2943\n",
       "recrutador            2943\n",
       "dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_prospects.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "codigo_vaga               0\n",
       "titulo                 2943\n",
       "modalidade            55019\n",
       "nome                      0\n",
       "codigo                    0\n",
       "situacao_candidado        0\n",
       "data_candidatura          0\n",
       "ultima_atualizacao     3913\n",
       "comentario            39201\n",
       "recrutador                0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df_prospects == \"\").sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extraindo apenas colunas que achamos relevantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prospects = df_prospects[[\"codigo\",\"codigo_vaga\",\"titulo\",\"situacao_candidado\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "codigo                2943\n",
       "codigo_vaga              0\n",
       "titulo                   0\n",
       "situacao_candidado    2943\n",
       "dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_prospects.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removemos as linhas em branco, pois identificamos que a coluna 'codigo' contém esses valores vazios e consideramos essa coluna essencial para o nosso processo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prospects.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(53759, 4)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_prospects.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "codigo                0\n",
       "codigo_vaga           0\n",
       "titulo                0\n",
       "situacao_candidado    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df_prospects == \"\").sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neste passo, criamos uma nova coluna chamada `situacao_candidado` no DataFrame `df_prospects`, com valores binários (1 ou 0), onde:\n",
    "- **1**: para candidatos com status de \"Aprovado\" (ou status relacionados, como \"Proposta Aceita\" ou \"Contratado pela Decision\").\n",
    "- **0**: para os candidatos que possuem status de \"Não Aprovado\" ou qualquer outro status que não indique aprovação.\n",
    "\n",
    "#### Etapas:\n",
    "\n",
    "1. **Definição dos status**: \n",
    "   - `status_aprovado`: Contém todos os status que indicam que o candidato foi aprovado.\n",
    "   - `status_negado`: Inclui os status que indicam que o candidato não foi aprovado.\n",
    "\n",
    "2. **Limpeza do status**: A função `str.strip()` é aplicada para remover espaços extras antes ou depois do texto em cada linha da coluna `situacao_candidado`.\n",
    "\n",
    "3. **Aplicação da lógica**: A função `apply` é usada para aplicar a condição:\n",
    "   - Se o valor da coluna `situacao_candidado` estiver na lista `status_aprovado`, o valor será 1.\n",
    "   - Caso contrário, o valor será 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Encaminhado ao Requisitante', 'Contratado pela Decision',\n",
       "       'Desistiu', 'Documentação PJ', 'Não Aprovado pelo Cliente',\n",
       "       'Prospect', 'Não Aprovado pelo RH', 'Aprovado',\n",
       "       'Não Aprovado pelo Requisitante', 'Inscrito', 'Entrevista Técnica',\n",
       "       'Em avaliação pelo RH', 'Contratado como Hunting',\n",
       "       'Desistiu da Contratação', 'Entrevista com Cliente',\n",
       "       'Documentação CLT', 'Recusado', 'Documentação Cooperado',\n",
       "       'Sem interesse nesta vaga', 'Encaminhar Proposta',\n",
       "       'Proposta Aceita'], dtype=object)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_prospects['situacao_candidado'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "status_aprovado = [\n",
    "    'Aprovado',\n",
    "    'Contratado pela Decision',\n",
    "    'Contratado como Hunting',\n",
    "    'Proposta Aceita',\n",
    "    'Encaminhar Proposta'\n",
    "]\n",
    "\n",
    "status_negado = [\n",
    "    'Não Aprovado pelo Cliente',\n",
    "    'Não Aprovado pelo RH',\n",
    "    'Não Aprovado pelo Requisitante',\n",
    "    'Desistiu',\n",
    "    'Desistiu da Contratação',\n",
    "    'Recusado',\n",
    "    'Sem interesse nesta vaga'\n",
    "]\n",
    "\n",
    "df_prospects['situacao_candidado'] = df_prospects['situacao_candidado'].str.strip()\n",
    "\n",
    "df_prospects['situacao_candidado'] = df_prospects['situacao_candidado'].apply(\n",
    "    lambda x: 1 if x in status_aprovado else 0\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "situacao_candidado\n",
       "0    50563\n",
       "1     3196\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_prospects['situacao_candidado'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prospects_concatenado = df_prospects[['codigo','situacao_candidado']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "codigo                object\n",
       "situacao_candidado     int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_prospects_concatenado.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prospects_concatenado.rename(columns={'codigo': 'codigo_profissional'}, inplace=True)\n",
    "df_prospects_concatenado['codigo_profissional'] = df_prospects_concatenado['codigo_profissional'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Criamos um dataframe para excluir os candidatos já aprovados, pois entendemos que não faz sentido incluí-los no retorno, dado que estamos focados na busca por novas contratações."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "deletar_aprovados = df_prospects_concatenado[df_prospects_concatenado['situacao_candidado'] == 1]['codigo_profissional']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A tabela Prospects contém dados duplicados, pois um mesmo candidato pode estar vinculado a mais de uma vaga de prospecção. Para lidar com isso, contabilizamos o número de prospecções associadas a cada candidato e garantimos que cada um seja tratado de forma única. Dessa forma, conseguimos incorporar essa informação ao nosso modelo de similaridade."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prospects_tratado = df_prospects_concatenado[df_prospects_concatenado['situacao_candidado'] == 0].groupby(by='codigo_profissional').count().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prospects_tratado.rename(columns={'situacao_candidado':'quantidade_prospect'},inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neste trecho, realizamos um left join para priorizar a tabela de candidatos, uma vez que entendemos que nem todos os candidatos foram prospectados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge = pd.merge(df_unico, df_prospects_tratado, on=['codigo_profissional'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge = df_merge[~df_merge['codigo_profissional'].isin(deletar_aprovados)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge['quantidade_prospect'].fillna(0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge['quantidade_prospect'] = df_merge['quantidade_prospect'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "codigo_profissional               27012\n",
       "perfil_concatenado_hard_skills    10808\n",
       "perfil_concatenado_education       1802\n",
       "perfil_concatenado_personal         997\n",
       "quantidade_prospect                  35\n",
       "dtype: int64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merge.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Realizamos a separação dos dados em DataFrames distintos, de acordo com o tipo de skill, para que os pesos pudessem ser aplicados de forma individualizada em cada grupo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hard_skills = df_merge[[\"codigo_profissional\", \"perfil_concatenado_hard_skills\", \"quantidade_prospect\"]].copy()\n",
    "\n",
    "df_education = df_merge[[\"codigo_profissional\", \"perfil_concatenado_education\"]].copy()\n",
    "\n",
    "df_personal = df_merge[[\"codigo_profissional\", \"perfil_concatenado_personal\"]].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Tratando a tabela df_vagas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['codigo_vaga', 'data_requicisao', 'limite_esperado_para_contratacao',\n",
       "       'titulo_vaga', 'vaga_sap', 'cliente', 'solicitante_cliente',\n",
       "       'empresa_divisao', 'requisitante', 'analista_responsavel',\n",
       "       'tipo_contratacao', 'prazo_contratacao', 'objetivo_vaga',\n",
       "       'prioridade_vaga', 'origem_vaga', 'superior_imediato', 'nome',\n",
       "       'telefone', 'data_inicial', 'data_final', 'nome_substituto', 'pais',\n",
       "       'estado', 'cidade', 'bairro', 'regiao', 'local_trabalho',\n",
       "       'vaga_especifica_para_pcd', 'faixa_etaria', 'horario_trabalho',\n",
       "       'nivel profissional', 'nivel_academico', 'nivel_ingles',\n",
       "       'nivel_espanhol', 'outro_idioma', 'areas_atuacao',\n",
       "       'principais_atividades', 'competencia_tecnicas_e_comportamentais',\n",
       "       'demais_observacoes', 'viagens_requeridas', 'equipamentos_necessarios',\n",
       "       'habilidades_comportamentais_necessarias', 'valor_venda',\n",
       "       'valor_compra_1', 'valor_compra_2'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_vagas.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "colunas_vagas = [\n",
    "    'codigo_vaga',\n",
    "    'titulo_vaga',\n",
    "    'vaga_especifica_para_pcd',\n",
    "    'nivel profissional',\n",
    "    'nivel_academico',\n",
    "    'nivel_ingles',\n",
    "    'nivel_espanhol',\n",
    "    'outro_idioma',\n",
    "    'areas_atuacao',\n",
    "    'principais_atividades',\n",
    "    'competencia_tecnicas_e_comportamentais',\n",
    "    'estado',\n",
    "    'cidade'\n",
    "]\n",
    "\n",
    "df_vagas = df_vagas[colunas_vagas]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nesses blocos tratamos algumas incosistências nas colunas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vagas['titulo_vaga'] = df_vagas['titulo_vaga'].str.replace(r'\\b\\w*\\d+\\s*-\\s*', '', regex=True).str.strip()\n",
    "df_vagas['titulo_vaga'] = df_vagas['titulo_vaga'].str.replace(r'\\s*-\\s*\\d+$', '', regex=True).str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vagas['principais_atividades'] = (\n",
    "    df_vagas['principais_atividades']\n",
    "    .str.replace(r'\\n+', ' ', regex=True)   \n",
    "    .str.replace('•', '')\n",
    "    .str.replace('', '')                  \n",
    "    .str.strip()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vagas['competencia_tecnicas_e_comportamentais'] = (\n",
    "    df_vagas['competencia_tecnicas_e_comportamentais']\n",
    "    .str.replace(r'\\n+', ' ', regex=True)   \n",
    "    .str.replace('•', '')\n",
    "    .str.replace('', '')                  \n",
    "    .str.strip()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "codigo_vaga                               0\n",
       "titulo_vaga                               0\n",
       "vaga_especifica_para_pcd                  0\n",
       "nivel profissional                        0\n",
       "nivel_academico                           0\n",
       "nivel_ingles                              0\n",
       "nivel_espanhol                            0\n",
       "outro_idioma                              0\n",
       "areas_atuacao                             0\n",
       "principais_atividades                     0\n",
       "competencia_tecnicas_e_comportamentais    0\n",
       "estado                                    0\n",
       "cidade                                    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_vagas.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "codigo_vaga                                   0\n",
       "titulo_vaga                                   0\n",
       "vaga_especifica_para_pcd                   1948\n",
       "nivel profissional                            0\n",
       "nivel_academico                               0\n",
       "nivel_ingles                                  0\n",
       "nivel_espanhol                             1304\n",
       "outro_idioma                              13708\n",
       "areas_atuacao                                15\n",
       "principais_atividades                         3\n",
       "competencia_tecnicas_e_comportamentais        6\n",
       "estado                                       11\n",
       "cidade                                       51\n",
       "dtype: int64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df_vagas == \"\").sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vagas.rename(columns={\"nivel profissional\":\"nivel_profissional\"},inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizamos este método para concatenar as colunas do df_vagas, com o objetivo de prepará-las para o processamento de NLP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "hard_skills_vagas = [\n",
    "    \"titulo_vaga\"\n",
    "    ,\"areas_atuacao\"\n",
    "    ,\"principais_atividades\"\n",
    "    ,\"competencia_tecnicas_e_comportamentais\"\n",
    "    ,\"nivel_profissional\"\n",
    "]\n",
    "\n",
    "education_vagas = [\n",
    "    \"nivel_academico\"\n",
    "    ,\"nivel_ingles\"\n",
    "    ,\"nivel_espanhol\"\n",
    "    ,\"outro_idioma\"  \n",
    "]\n",
    "\n",
    "personal_vagas = [\n",
    "    \"vaga_especifica_para_pcd\"\n",
    "    ,\"estado\"\n",
    "    ,\"cidade\"\n",
    "]\n",
    "\n",
    "grupos_colunas_vagas = {\n",
    "    \"hard_skills_vagas\": hard_skills_vagas,\n",
    "    \"education_vagas\": education_vagas,\n",
    "    \"personal_vagas\": personal_vagas\n",
    "}\n",
    "\n",
    "dfs_por_grupo_vaga = criar_grupos_concatenados(df_vagas, \"codigo_vaga\", grupos_colunas_vagas)\n",
    "\n",
    "\n",
    "df_hard_skills_vagas = dfs_por_grupo_vaga[\"hard_skills_vagas\"]\n",
    "df_education_vagas = dfs_por_grupo_vaga[\"education_vagas\"]\n",
    "df_personal_vagas = dfs_por_grupo_vaga[\"personal_vagas\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.0 Aplicando o processo de NLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Este bloco tem como objetivo transformar os textos concatenados em vetores de embeddings utilizando o modelo all-MiniLM-L12-v2 da biblioteca SentenceTransformer.\n",
    " Ao converter os textos das colunas em representações vetoriais, conseguimos capturar o contexto semântico de cada entrada.\n",
    " Esses vetores serão utilizados posteriormente para calcular a similaridade entre candidatos e vagas, viabilizando uma análise mais precisa de compatibilidade."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removemos as linhas em branco desses dois DataFrames, pois, como foram extraídas do df_merge, já estavam nulas — indicando que o candidato não possuía essas informações preenchidas. Essa limpeza foi feita com o objetivo de reduzir o custo computacional no processamento dos embeddings, eliminando os registros irrelevantes antes da execução do método."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_personal = df_personal[df_personal['perfil_concatenado_personal'] != '']\n",
    "df_education = df_education[df_education['perfil_concatenado_education'] != '']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A função `gerar_embeddings` tem como objetivo transformar informações textuais de uma coluna de um DataFrame em vetores numéricos (embeddings)\n",
    "\n",
    "#### Etapas:\n",
    "1. **Conversão para String**: A coluna de texto é convertida para tipo string para garantir que todos os dados sejam manipulados de forma consistente.\n",
    "   \n",
    "2. **Geração dos Embeddings**: Utilizando o modelo pré-treinado `all-MiniLM-L12-v2`, os textos são transformados em vetores de alta dimensionalidade. A função `encode` da biblioteca **SentenceTransformer** gera esses vetores.\n",
    "\n",
    "3. **Criação de DataFrame para Embeddings**: A função cria um DataFrame contendo os embeddings gerados, nomeando cada coluna com base no prefixo fornecido e no índice da dimensão do embedding.\n",
    "\n",
    "4. **Concatenação com o DataFrame Original**: Os embeddings gerados são concatenados com o DataFrame original para que cada candidato possua seu vetor de embeddings associado.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 845/845 [02:55<00:00,  4.81it/s]\n",
      "Batches: 100%|██████████| 225/225 [00:50<00:00,  4.42it/s]\n",
      "Batches: 100%|██████████| 486/486 [00:37<00:00, 13.06it/s]\n"
     ]
    }
   ],
   "source": [
    "model = SentenceTransformer('all-MiniLM-L12-v2')\n",
    "\n",
    "def gerar_embeddings(df, coluna_texto, prefixo_nome_embedding):\n",
    "    df = df.copy()\n",
    "    df[coluna_texto] = df[coluna_texto].astype(str)\n",
    "    \n",
    "    embeddings = model.encode(df[coluna_texto].tolist(), show_progress_bar=True)\n",
    "    embeddings_df = pd.DataFrame(\n",
    "        embeddings,\n",
    "        columns=[f'{prefixo_nome_embedding}_embedding_{i}' for i in range(embeddings.shape[1])]\n",
    "    )\n",
    "    \n",
    "    return pd.concat([df.reset_index(drop=True), embeddings_df], axis=1)\n",
    "\n",
    "df_hard_skills_embed = gerar_embeddings(df_hard_skills, 'perfil_concatenado_hard_skills', 'hard')\n",
    "df_education_embed = gerar_embeddings(df_education, 'perfil_concatenado_education', 'edu')\n",
    "df_personal_embed = gerar_embeddings(df_personal, 'perfil_concatenado_personal', 'pers')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neste dicionário, definimos os pesos atribuídos a cada tipo de informação (por exemplo, hard skills, educação, características pessoais), com o objetivo de equilibrar a influência de cada uma durante o cálculo de similaridade. Essa ponderação evita que determinados grupos de atributos dominem a análise, garantindo resultados mais justos e representativos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "pesos = {\n",
    "    'hard_skills': 0.6,\n",
    "    'education': 0.3,\n",
    "    'personal': 0.1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aplicar_peso(df_embed, peso, prefixo):\n",
    "    cols_embed = [col for col in df_embed.columns if col.startswith(prefixo)]\n",
    "    df_embed[cols_embed] = df_embed[cols_embed] * peso\n",
    "    return df_embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hard_skills_embed = aplicar_peso(df_hard_skills_embed, pesos['hard_skills'], 'hard')\n",
    "df_education_embed = aplicar_peso(df_education_embed, pesos['education'], 'edu')\n",
    "df_personal_embed = aplicar_peso(df_personal_embed, pesos['personal'], 'pers')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Após aplicar os pesos em todos os DataFrames de embeddings, realizamos a união desses dados em um único DataFrame consolidado. Essa fusão nos permite utilizar a representação vetorial completa de cada candidato para o cálculo de similaridade de forma integrada e balanceada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp = df_hard_skills_embed.merge(\n",
    "    df_education_embed, on='codigo_profissional', how='left', suffixes=('', '_edu')\n",
    ")\n",
    "\n",
    "df_final = df_temp.merge(\n",
    "    df_personal_embed, on='codigo_profissional', how='left', suffixes=('', '_pers')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removemos algumas colunas indesejadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final_candidatos = df_final[df_final.columns[~df_final.columns.str.contains(\"perfil_concatenado\", case=False)]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como resultado do processo de junção (left join) entre os DataFrames de embeddings, muitas colunas apresentam valores nulos devido à ausência de informações em determinados perfis. Para manter a consistência dos vetores e viabilizar o cálculo da similaridade do cosseno, optamos por substituir os valores nulos por zero. Essa abordagem é adequada, pois a presença de zeros em embeddings simplesmente indica ausência de informação naquela dimensão, sem comprometer a integridade do cálculo de similaridade."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final_candidatos.fillna(0,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aqui aplicamos o mesmo processo que efetuamos nos candidatos, porém com as vagas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 441/441 [04:33<00:00,  1.61it/s]\n",
      "Batches: 100%|██████████| 441/441 [01:24<00:00,  5.22it/s]\n",
      "Batches: 100%|██████████| 441/441 [01:04<00:00,  6.88it/s]\n"
     ]
    }
   ],
   "source": [
    "df_hard_skills_embed_vaga = gerar_embeddings(df_hard_skills_vagas, 'perfil_concatenado_hard_skills_vagas', 'vhard')\n",
    "df_education_embed_vaga = gerar_embeddings(df_education_vagas, 'perfil_concatenado_education_vagas', 'vedu')\n",
    "df_personal_embed_vaga = gerar_embeddings(df_personal_vagas, 'perfil_concatenado_personal_vagas', 'vpers')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aplicamos os mesmos pesos, para ter a mesma magnitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hard_skills_vaga_embed = aplicar_peso(df_hard_skills_embed_vaga, pesos['hard_skills'], 'vhard')\n",
    "df_education_vaga_embed = aplicar_peso(df_education_embed_vaga, pesos['education'], 'vedu')\n",
    "df_personal_vaga_embed = aplicar_peso(df_personal_embed_vaga, pesos['personal'], 'vpers')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Realizamos o left join e a mesma tratativa dos valores nulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vagas_embed = df_hard_skills_vaga_embed.merge(\n",
    "    df_education_vaga_embed, on='codigo_vaga', how='left'\n",
    ").merge(\n",
    "    df_personal_vaga_embed, on='codigo_vaga', how='left'\n",
    ")\n",
    "\n",
    "df_vagas_embed.fillna(0, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retiramos algumas colunas indesejadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final_vagas = df_vagas_embed[df_vagas_embed.columns[~df_vagas_embed.columns.str.contains(\"perfil_concatenado\", case=False)]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.0 Função de Recomendação de Candidatos com Similaridade de Cosseno\n",
    "\n",
    "Esta função realiza a recomendação de candidatos com base na similaridade de cosseno entre os vetores de embeddings completos (hard skills, formação e perfil pessoal) de candidatos e da vaga especificada.\n",
    "\n",
    "### Parâmetros de entrada:\n",
    "- `codigo_vaga_input`: Código da vaga usada como referência.\n",
    "- `df_candidatos_final`: DataFrame consolidado com todos os embeddings dos candidatos.\n",
    "- `df_vagas_final`: DataFrame consolidado com todos os embeddings das vagas.\n",
    "- `top_n`: Número de candidatos mais similares a serem retornados (padrão = 5).\n",
    "\n",
    "### Etapas:\n",
    "1. Filtra a vaga correspondente ao código informado.\n",
    "2. Seleciona todas as colunas que contenham a palavra `'embedding'` no nome, garantindo que todos os vetores (hard, education e personal) sejam considerados.\n",
    "3. Extrai o vetor completo da vaga e os vetores dos candidatos.\n",
    "4. Calcula a similaridade de cosseno entre o vetor da vaga e os vetores dos candidatos.\n",
    "5. Adiciona o score de similaridade ao DataFrame de candidatos.\n",
    "6. Ordena os candidatos por `score_cosine` de forma decrescente.\n",
    "7. Retorna os `top_n` candidatos mais similares, incluindo o `codigo_profissional`, o `score_cosine` e a `quantidade_prospect`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recomendar_candidatos_cosine(codigo_vaga_input, df_candidatos_final, df_vagas_final, top_n=5):\n",
    "\n",
    "    vaga_embed = df_vagas_final[df_vagas_final['codigo_vaga'] == codigo_vaga_input]\n",
    "    if vaga_embed.empty:\n",
    "        return \"Vaga não encontrada.\"\n",
    "\n",
    "    embedding_cols_vaga = [col for col in df_vagas_final.columns if 'embedding' in col]\n",
    "    embedding_cols_candidatos = [col for col in df_candidatos_final.columns if 'embedding' in col]\n",
    "\n",
    "    vaga_vector = vaga_embed[embedding_cols_vaga].values\n",
    "\n",
    "    candidatos_disponiveis = df_candidatos_final\n",
    "\n",
    "    candidatos_vectors = candidatos_disponiveis[embedding_cols_candidatos].values\n",
    "\n",
    "    sim_scores = cosine_similarity(candidatos_vectors, vaga_vector).flatten()\n",
    "    candidatos_disponiveis['score_cosine'] = sim_scores\n",
    "\n",
    "    candidatos_disponiveis['score_cosine_percentual'] = (candidatos_disponiveis['score_cosine'] * 100).round(2).astype(str) + '%'\n",
    "\n",
    "    df_applicants['codigo_profissional'] = df_applicants['codigo_profissional'].astype(int)\n",
    "\n",
    "    candidatos_com_info = candidatos_disponiveis.merge(\n",
    "        df_applicants[['codigo_profissional', 'objetivo_profissional']], \n",
    "        on='codigo_profissional', \n",
    "        how='left'\n",
    "    )\n",
    "\n",
    "    return candidatos_com_info.sort_values('score_cosine', ascending=False).head(top_n)[\n",
    "        ['codigo_profissional','objetivo_profissional','score_cosine_percentual','quantidade_prospect']\n",
    "    ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>codigo_profissional</th>\n",
       "      <th>objetivo_profissional</th>\n",
       "      <th>score_cosine_percentual</th>\n",
       "      <th>quantidade_prospect</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3919</th>\n",
       "      <td>14320</td>\n",
       "      <td>Desenvolvedor Web</td>\n",
       "      <td>82.21%</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2135</th>\n",
       "      <td>12</td>\n",
       "      <td>Desenvolvedor Web</td>\n",
       "      <td>81.75%</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6421</th>\n",
       "      <td>21126</td>\n",
       "      <td>Desenvolvedor .NET</td>\n",
       "      <td>81.07%</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6066</th>\n",
       "      <td>20033</td>\n",
       "      <td>Analista de Sistemas, Full Stack .Net Core, An...</td>\n",
       "      <td>80.97%</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6063</th>\n",
       "      <td>20027</td>\n",
       "      <td>Web Designer ou Desenvolvedor</td>\n",
       "      <td>80.76%</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      codigo_profissional                              objetivo_profissional  \\\n",
       "3919                14320                                  Desenvolvedor Web   \n",
       "2135                   12                                  Desenvolvedor Web   \n",
       "6421                21126                                 Desenvolvedor .NET   \n",
       "6066                20033  Analista de Sistemas, Full Stack .Net Core, An...   \n",
       "6063                20027                      Web Designer ou Desenvolvedor   \n",
       "\n",
       "     score_cosine_percentual  quantidade_prospect  \n",
       "3919                  82.21%                    1  \n",
       "2135                  81.75%                    0  \n",
       "6421                  81.07%                    4  \n",
       "6066                  80.97%                    6  \n",
       "6063                  80.76%                    1  "
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "codigo_vaga = 5180\n",
    "\n",
    "\n",
    "result = recomendar_candidatos_cosine(codigo_vaga, df_final_candidatos, df_final_vagas, top_n=5)\n",
    "\n",
    "result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
